{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jpyneni/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords = stopwords.words('english')\n",
    "spaces = set()\n",
    "space_text = []\n",
    "for i in range(5):\n",
    "    s = \" \"*(i+1)\n",
    "    spaces.add(s)\n",
    "spaces.add('')\n",
    "\n",
    "def clean_column(dataframe, column_to_clean, new_col):\n",
    "    df_copy = dataframe.copy()\n",
    "    df_copy['copied_column'] = df_copy[column_to_clean]\n",
    "    \n",
    "    # Making all characters lowercase\n",
    "    df_copy['copied_column'] = df_copy['copied_column'].str.lower()\n",
    "    \n",
    "    cleaned_column = []\n",
    "    for label in df_copy.index:\n",
    "    \n",
    "        row = df_copy.loc[label, :]['copied_column']\n",
    "        clean = []\n",
    "\n",
    "        # Removing all punctuation\n",
    "        for x in row.split():\n",
    "            for p in '!\"$%&\\'()*+,-./:;<=>?@[\\\\]“”^_`{|}~’': # optional: !\n",
    "                x = x.replace(p, '')\n",
    "            clean.append(x)\n",
    "\n",
    "        # Removing all stop words\n",
    "        clean = [x for x in clean if x not in nltk_stopwords]\n",
    "\n",
    "        # Removing all numerical digits\n",
    "        for i in range(len(clean)):\n",
    "            x = clean[i]\n",
    "            for d in string.digits:\n",
    "                x = x.replace(d, '')\n",
    "            clean[i] = x\n",
    "\n",
    "        # Removing all single-character words\n",
    "        clean = [x for x in clean if len(x) != 1]\n",
    "        clean = \" \".join(clean)\n",
    "        clean = clean.encode('ascii', 'ignore').decode('ascii') #take out emojis\n",
    "        clean = clean.strip()\n",
    "        cleaned_column.append(clean)\n",
    "    df_copy[new_col] = cleaned_column\n",
    "    del df_copy['copied_column']\n",
    "    return df_copy\n",
    "\n",
    "def semi_clean_column(dataframe, column_to_clean, new_col):\n",
    "    df_copy = dataframe.copy()\n",
    "    df_copy['copied_column'] = df_copy[column_to_clean]\n",
    "    \n",
    "    # Making all characters lowercase\n",
    "    df_copy['copied_column'] = df_copy['copied_column'].str.lower()\n",
    "    \n",
    "    cleaned_column = []\n",
    "    for label in df_copy.index:\n",
    "        \n",
    "        row = df_copy.loc[label, :]['copied_column']\n",
    "        row = row.encode('ascii', 'ignore').decode('ascii') #take out emojis\n",
    "        cleaned_column.append(row)\n",
    "    df_copy[new_col] = cleaned_column\n",
    "    del df_copy['copied_column']\n",
    "    return df_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  \\\n",
      "0  enunciate the annies listing political group s...   \n",
      "1  when did the decline of char start? it come ou...   \n",
      "2  sir edmund percival hillary dewitt clinton con...   \n",
      "3  health care reclaim legislation is likely to m...   \n",
      "4  the economical turnaround set about at the ter...   \n",
      "\n",
      "                                         clean_title  label  \n",
      "0  says the annies list political group supports ...      0  \n",
      "1  when did the decline of coal start? it started...      1  \n",
      "2  hillary clinton agrees with john mccain \"by vo...      1  \n",
      "3  health care reform legislation is likely to ma...      0  \n",
      "4  the economic turnaround started at the end of ...      1  \n",
      "(12791, 3)\n",
      "\n",
      "                                          clean_text  \\\n",
      "0  firm dem aide: we didnt tied learn comeys lett...   \n",
      "1  eer perplex the tactile sensation your livelin...   \n",
      "2  why the accuracy power dumbfound you provoke o...   \n",
      "3  tv  civilian wipe out in unmarried the states ...   \n",
      "4  print \\nan irani womanhood has been sentenced ...   \n",
      "\n",
      "                                         clean_title  label  \n",
      "0  house dem aide: we didnt even see comeys lette...      0  \n",
      "1  flynn: hillary clinton, big woman on campus - ...      1  \n",
      "2                  why the truth might get you fired      0  \n",
      "3  15 civilians killed in single us airstrike hav...      0  \n",
      "4  iranian woman jailed for fictional unpublished...      0  \n",
      "(10063, 3)\n",
      "\n",
      "                                          clean_text  \\\n",
      "0  share on chirrup \\nthe republican river subjec...   \n",
      "1  home  newspaper headline  world wide tidings  ...   \n",
      "2  zero  ii  : fotodom.ru/ \\n,        upcountry g...   \n",
      "3  keywords: forbiddance on cannabis sativa , dec...   \n",
      "4  microsoft withhold a dislodge plot of ground f...   \n",
      "\n",
      "                                         clean_title  label  \n",
      "0  new rnc ad campaign reminds voters obamacare w...      0  \n",
      "1  fbi discovered emails weeks ago, stash include...      0  \n",
      "2                                                  ?      0  \n",
      "3  why marijuana should be legalized across the g...      0  \n",
      "4  report: microsoft withheld free cyber attack p...      1  \n",
      "(10064, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1_unclean = pd.read_csv('../Augmentation Data/LIAR_SR.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df2_unclean = pd.read_csv('../Augmentation Data/Kaggle2_Mixed_SR_a.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df3_unclean = pd.read_csv('../Augmentation Data/Kaggle2_Mixed_SR_b.csv').drop(['Unnamed: 0'], axis=1)\n",
    "print(df1_unclean.head())\n",
    "print(df1_unclean.shape)\n",
    "print()\n",
    "print(df2_unclean.head())\n",
    "print(df2_unclean.shape)\n",
    "print()\n",
    "print(df3_unclean.head())\n",
    "print(df3_unclean.shape)\n",
    "print()\n",
    "\n",
    "for i in spaces:\n",
    "    df1_unclean = df1_unclean[(df1_unclean['clean_title'] != i) & \n",
    "                                  (df1_unclean['clean_text'] != i)]\n",
    "    df2_unclean = df2_unclean[(df2_unclean['clean_title'] != i) & \n",
    "                                  (df2_unclean['clean_text'] != i)]\n",
    "    df3_unclean = df3_unclean[(df3_unclean['clean_title'] != i) & \n",
    "                                  (df3_unclean['clean_text'] != i)]\n",
    "\n",
    "df1_unclean['clean_title'] = df1_unclean['clean_title'].apply(lambda x: str(x))\n",
    "df1_unclean['clean_text'] = df1_unclean['clean_text'].apply(lambda x: str(x))\n",
    "df1_unclean = df1_unclean[(df1_unclean['clean_title'] != 'nan') & \n",
    "                                  (df1_unclean['clean_text'] != 'nan')]\n",
    "\n",
    "df2_unclean['clean_title'] = df2_unclean['clean_title'].apply(lambda x: str(x))\n",
    "df2_unclean['clean_text'] = df2_unclean['clean_text'].apply(lambda x: str(x))\n",
    "df2_unclean = df2_unclean[(df2_unclean['clean_title'] != 'nan') & \n",
    "                                  (df2_unclean['clean_text'] != 'nan') ]\n",
    "\n",
    "\n",
    "df3_unclean['clean_title'] = df3_unclean['clean_title'].apply(lambda x: str(x))\n",
    "df3_unclean['clean_text'] = df3_unclean['clean_text'].apply(lambda x: str(x))\n",
    "df3_unclean = df3_unclean[(df3_unclean['clean_title'] != 'nan') & \n",
    "                                  (df3_unclean['clean_text'] != 'nan')]\n",
    "\n",
    "\n",
    "# df1_clean = clean_column(df1_unclean, 'clean_text', 'clean_text')\n",
    "# df1_clean = clean_column(df1_clean, 'clean_title', 'clean_title')\n",
    "# # df_real_clean.drop(['url','title', 'text'],inplace=True,axis=1)\n",
    "# df1_clean.head()\n",
    "# # df_real_clean.to_csv('../Cleaned Data/Real_News.csv')\n",
    "\n",
    "# # df_hf_clean = semi_clean_column(df_hf_unclean, 'text', 'clean_text')\n",
    "# # df_hf_clean = semi_clean_column(df_hf_clean, 'title', 'clean_title')\n",
    "# # df_hf_clean = df_hf_clean[['clean_text', 'clean_title']]\n",
    "# # df_hf_clean.head()\n",
    "# # df_hf_clean.to_csv('../Cleaned Data/Human_Fake_News.csv')\n",
    "\n",
    "# # df_nf_clean = semi_clean_column(df_nf_unclean, 'text', 'clean_text')\n",
    "# # df_nf_clean = semi_clean_column(df_nf_clean, 'title', 'clean_title')\n",
    "# # df_nf_clean.to_csv('../Cleaned Data/Neural_Fake_News.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12791, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>enunciate annies listing political group suppo...</td>\n",
       "      <td>says annies list political group supports thir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>decline char start come instinctive brag subsc...</td>\n",
       "      <td>decline coal start started natural gas took st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sir edmund percival hillary dewitt clinton con...</td>\n",
       "      <td>hillary clinton agrees john mccain voting give...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>health care reclaim legislation likely mandate...</td>\n",
       "      <td>health care reform legislation likely mandate ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>economical turnaround set terminal term</td>\n",
       "      <td>economic turnaround started end term</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  enunciate annies listing political group suppo...   \n",
       "1  decline char start come instinctive brag subsc...   \n",
       "2  sir edmund percival hillary dewitt clinton con...   \n",
       "3  health care reclaim legislation likely mandate...   \n",
       "4            economical turnaround set terminal term   \n",
       "\n",
       "                                         clean_title  label  \n",
       "0  says annies list political group supports thir...      0  \n",
       "1  decline coal start started natural gas took st...      1  \n",
       "2  hillary clinton agrees john mccain voting give...      1  \n",
       "3  health care reform legislation likely mandate ...      0  \n",
       "4               economic turnaround started end term      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_clean = clean_column(df1_unclean, 'clean_text', 'clean_text')\n",
    "df1_clean = clean_column(df1_clean, 'clean_title', 'clean_title')\n",
    "# df_real_clean.drop(['url','title', 'text'],inplace=True,axis=1)\n",
    "print(df1_clean.shape)\n",
    "df1_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10049, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>firm dem aide didnt tied learn comeys letter a...</td>\n",
       "      <td>house dem aide didnt even see comeys letter ja...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eer perplex tactile sensation liveliness band ...</td>\n",
       "      <td>flynn hillary clinton big woman campus  breitbart</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>accuracy power dumbfound provoke oct   tautnes...</td>\n",
       "      <td>truth might get fired</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>tv civilian wipe unmarried states airstrike me...</td>\n",
       "      <td>civilians killed single us airstrike identified</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>print irani womanhood sentenced geezerhood pri...</td>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  firm dem aide didnt tied learn comeys letter a...   \n",
       "1  eer perplex tactile sensation liveliness band ...   \n",
       "2  accuracy power dumbfound provoke oct   tautnes...   \n",
       "3  tv civilian wipe unmarried states airstrike me...   \n",
       "4  print irani womanhood sentenced geezerhood pri...   \n",
       "\n",
       "                                         clean_title  label  \n",
       "0  house dem aide didnt even see comeys letter ja...      0  \n",
       "1  flynn hillary clinton big woman campus  breitbart      1  \n",
       "2                              truth might get fired      0  \n",
       "3    civilians killed single us airstrike identified      0  \n",
       "4  iranian woman jailed fictional unpublished sto...      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_clean = clean_column(df2_unclean, 'clean_text', 'clean_text')\n",
    "df2_clean = clean_column(df2_clean, 'clean_title', 'clean_title')\n",
    "print(df2_clean.shape)\n",
    "# df_real_clean.drop(['url','title', 'text'],inplace=True,axis=1)\n",
    "df2_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10056, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>share chirrup republican river subject commiss...</td>\n",
       "      <td>new rnc ad campaign reminds voters obamacare o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>home newspaper headline world wide tidings fed...</td>\n",
       "      <td>fbi discovered emails weeks ago stash includes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>zero ii  fotodomru  upcountry group      pravd...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>keywords forbiddance cannabis sativa  decrimin...</td>\n",
       "      <td>marijuana legalized across globe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>microsoft withhold dislodge plot ground user s...</td>\n",
       "      <td>report microsoft withheld free cyber attack pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  \\\n",
       "0  share chirrup republican river subject commiss...   \n",
       "1  home newspaper headline world wide tidings fed...   \n",
       "2  zero ii  fotodomru  upcountry group      pravd...   \n",
       "3  keywords forbiddance cannabis sativa  decrimin...   \n",
       "4  microsoft withhold dislodge plot ground user s...   \n",
       "\n",
       "                                         clean_title  label  \n",
       "0  new rnc ad campaign reminds voters obamacare o...      0  \n",
       "1  fbi discovered emails weeks ago stash includes...      0  \n",
       "2                                                         0  \n",
       "3                   marijuana legalized across globe      0  \n",
       "4  report microsoft withheld free cyber attack pa...      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_clean = clean_column(df3_unclean, 'clean_text', 'clean_text')\n",
    "df3_clean = clean_column(df3_clean, 'clean_title', 'clean_title')\n",
    "print(df3_clean.shape)\n",
    "# df_real_clean.drop(['url','title', 'text'],inplace=True,axis=1)\n",
    "df3_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_clean.to_csv('../Augmentation Data/LIAR_SR_clean.csv')\n",
    "df2_clean.to_csv('../Augmentation Data/Kaggle2_Mixed_SR_a_clean.csv')\n",
    "df3_clean.to_csv('../Augmentation Data/Kaggle2_Mixed_SR_b_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hf_clean = df_hf_clean[['site_url','clean_text']]\n",
    "# df_hf_clean.head()\n",
    "# df_hf_clean.to_csv('../Cleaned Data/Human_Fake_News.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
