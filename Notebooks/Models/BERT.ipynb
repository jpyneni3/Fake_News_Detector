{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd0ec3bdcd60446483916ceee132dfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_064b68a998574f9d945bd4df2bffde4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c32aefe41888479cb4d3b8263e81a157",
              "IPY_MODEL_e1f539aebea44f68ab6ee7bdd5c02ec6"
            ]
          }
        },
        "064b68a998574f9d945bd4df2bffde4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c32aefe41888479cb4d3b8263e81a157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_647362e815ef4d4da8a074af927f8871",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_630673e01de042458bfb3aad25682bef"
          }
        },
        "e1f539aebea44f68ab6ee7bdd5c02ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_247a746e1877473a888a984df9c42fd1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:24&lt;00:00, 14.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73254e8113bb4549977c1676af7b15d3"
          }
        },
        "647362e815ef4d4da8a074af927f8871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "630673e01de042458bfb3aad25682bef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "247a746e1877473a888a984df9c42fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73254e8113bb4549977c1676af7b15d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65324e2fd407468fafb634a878659dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b15b6414466e4a2e89d45eaf2c0b353e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8785a7b52f46485a9b1844448d6eff78",
              "IPY_MODEL_98ade063470c4cd9897c91b6f1527a2a"
            ]
          }
        },
        "b15b6414466e4a2e89d45eaf2c0b353e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8785a7b52f46485a9b1844448d6eff78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dc63dbd30fd4c8f98f7dbe9c01880f4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1756c429fb34d13853506ab5c22ffed"
          }
        },
        "98ade063470c4cd9897c91b6f1527a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e29a76f89c224672996a4ad3e6bf1019",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:24&lt;00:00, 18.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60ac98e959d2440f9f1e04203466cf4f"
          }
        },
        "9dc63dbd30fd4c8f98f7dbe9c01880f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1756c429fb34d13853506ab5c22ffed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e29a76f89c224672996a4ad3e6bf1019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60ac98e959d2440f9f1e04203466cf4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFDiZ4l1CST6",
        "colab_type": "text"
      },
      "source": [
        "# BERT with Back Translation Augmentation \n",
        "## Real News and Fake News (~82k total)\n",
        "Class: Label\n",
        "\n",
        "Real: 1\n",
        "\n",
        "Fake: 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIKLTvFOnfXr",
        "colab_type": "code",
        "outputId": "ec2d1297-898d-4a87-9c01-76a5563bd899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUg3J8yPYBk1",
        "colab_type": "code",
        "outputId": "35235c3b-14fa-4c8f-f202-059bcc1c4431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIcFV6WWYDuE",
        "colab_type": "code",
        "outputId": "5eb8ebbe-6b40-4b53-9601-70228723595c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmbVxJPh24qB",
        "colab_type": "text"
      },
      "source": [
        "## No Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLvCxqc7YLpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "file = \"combined_{}.csv\"\n",
        "dfs = []\n",
        "for i in range(3):\n",
        "    fp = file.format(i+1)\n",
        "    read = pd.read_csv(fp)\n",
        "    read = read[['label', 'clean_text']]\n",
        "    dfs.append(read)\n",
        "\n",
        "dfs[2] = dfs[2][:-13000]\n",
        "\n",
        "data = pd.concat(dfs)\n",
        "data.tail()\n",
        "data.reset_index(inplace=True, drop=True)\n",
        "print('All Data:', data.shape)\n",
        "\n",
        "data.dropna(inplace=True)\n",
        "train_data, test_data = train_test_split(data, test_size=0.2)\n",
        "\n",
        "print('\\nTrain Data:', train_data.shape)\n",
        "print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "print('\\nTest Data:', test_data.shape)\n",
        "print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "sentences = train_data.clean_text.values\n",
        "labels = train_data.label.values\n",
        "\n",
        "train_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-T9snKg2tDv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Grover Augmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCuAnQ9W2ni-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grover Augmentation\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# import sklearn\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# file = \"combined_{}.csv\"\n",
        "# dfs = []\n",
        "# for i in range(3):\n",
        "#     fp = file.format(i+1)\n",
        "#     read = pd.read_csv(fp)\n",
        "#     read = read[['label', 'clean_text']]\n",
        "#     dfs.append(read)\n",
        "\n",
        "\n",
        "# real_news = dfs[2].copy()\n",
        "# dfs[2] = real_news[:-13000]\n",
        "# data = pd.concat(dfs)\n",
        "# data.tail()\n",
        "# data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "\n",
        "# data.dropna(inplace=True)\n",
        "# train_data, test_data = train_test_split(data, test_size=0.3)\n",
        "\n",
        "# print('Train Data:', train_data.shape)\n",
        "# print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "# print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# print('\\nTest Data:', test_data.shape)\n",
        "# print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "# print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "\n",
        "# grover_augmentation = pd.read_csv('Grover_clean.csv')[['label', 'clean_text']]\n",
        "# real_news_offset = real_news[-13000:]\n",
        "# train_data = pd.concat([train_data, grover_augmentation, real_news_offset])\n",
        "# train_data.dropna(inplace=True)\n",
        "\n",
        "# print('\\n-------------------------------After Augmentation -------------------------------\\n')\n",
        "# print('Train Data:', train_data.shape)\n",
        "# print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "# print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# print('\\nTest Data:', test_data.shape)\n",
        "# print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "# print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# sentences = train_data.clean_text.values\n",
        "# labels = train_data.label.values\n",
        "\n",
        "# train_data.head(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gys3_CxMRkog",
        "colab_type": "text"
      },
      "source": [
        "## Naive Synonym Replacement Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtArg9BnRzRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Naive Synonym Replacement\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# import sklearn\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# file = \"combined_{}.csv\"\n",
        "# dfs = []\n",
        "# for i in range(3):\n",
        "#     fp = file.format(i+1)\n",
        "#     read = pd.read_csv(fp)\n",
        "#     read = read[['label', 'clean_text']]\n",
        "#     dfs.append(read)\n",
        "\n",
        "# dfs[2] = dfs[2][:-13000]\n",
        "# data = pd.concat(dfs)\n",
        "# data.tail()\n",
        "# data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# data.dropna(inplace=True)\n",
        "# train_data, test_data = train_test_split(data, test_size=0.3)\n",
        "\n",
        "# print('Train Data:', train_data.shape)\n",
        "# print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "# print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# print('\\nTest Data:', test_data.shape)\n",
        "# print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "# print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "\n",
        "# nsr1 = pd.read_csv('Kaggle2_Mixed_SR_a_clean.csv')[['label', 'clean_text']]\n",
        "# nsr2 = pd.read_csv('Kaggle2_Mixed_SR_b_clean.csv')[['label', 'clean_text']]\n",
        "# nsr3 = pd.read_csv('LIAR_SR_clean.csv')[['label', 'clean_text']]\n",
        "\n",
        "# nsr_augmentation = pd.concat([nsr1, nsr2, nsr3])\n",
        "# train_data = pd.concat([train_data, nsr_augmentation])\n",
        "# train_data.dropna(inplace=True)\n",
        "\n",
        "# print('\\n-------------------------------After Augmentation -------------------------------\\n')\n",
        "# print('Train Data:', train_data.shape)\n",
        "# print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "# print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# print('\\nTest Data:', test_data.shape)\n",
        "# print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "# print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# sentences = train_data.clean_text.values\n",
        "# labels = train_data.label.values\n",
        "\n",
        "# train_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85vOOojiSzVK",
        "colab_type": "text"
      },
      "source": [
        "## Back Translation Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHwNj99uSrUJ",
        "colab_type": "code",
        "outputId": "a362a32e-57b7-4453-b383-3d6ffbb4fd35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "source": [
        "# Back Translation\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# import sklearn\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# file = \"combined_{}.csv\"\n",
        "# dfs = []\n",
        "# for i in range(3):\n",
        "#     fp = file.format(i+1)\n",
        "#     read = pd.read_csv(fp)\n",
        "#     read = read[['label', 'clean_text']]\n",
        "#     dfs.append(read)\n",
        "\n",
        "# dfs[2] = dfs[2][:-13000]\n",
        "# data = pd.concat(dfs)\n",
        "# data.tail()\n",
        "# data.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# data.dropna(inplace=True)\n",
        "# train_data, test_data = train_test_split(data, test_size=0.3)\n",
        "\n",
        "# print('Train Data:', train_data.shape)\n",
        "# print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "# print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# print('\\nTest Data:', test_data.shape)\n",
        "# print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "# print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "\n",
        "# bt1 = pd.read_csv('Kaggle2_Mixed_bt_clean.csv')[['label', 'clean_text']]\n",
        "# bt2 = pd.read_csv('LIAR_BT_clean.csv')[['label', 'clean_text']]\n",
        "\n",
        "# bt_augmentation = pd.concat([bt1, bt2])\n",
        "# train_data = pd.concat([train_data, bt_augmentation])\n",
        "# train_data.dropna(inplace=True)\n",
        "\n",
        "# print('\\n-------------------------------After Augmentation -------------------------------\\n')\n",
        "# print('Train Data:', train_data.shape)\n",
        "# print(train_data[train_data.label == 1].shape[0], \"Real\")\n",
        "# print(train_data[train_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# print('\\nTest Data:', test_data.shape)\n",
        "# print(test_data[test_data.label == 1].shape[0], \"Real\")\n",
        "# print(test_data[test_data.label == 0].shape[0], \"Fake\")\n",
        "\n",
        "# sentences = train_data.clean_text.values\n",
        "# labels = train_data.label.values\n",
        "\n",
        "# train_data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data: (41621, 2)\n",
            "22107 Real\n",
            "19514 Fake\n",
            "\n",
            "Test Data: (17838, 2)\n",
            "9342 Real\n",
            "8496 Fake\n",
            "\n",
            "-------------------------------After Augmentation -------------------------------\n",
            "\n",
            "Train Data: (64435, 2)\n",
            "33292 Real\n",
            "31143 Fake\n",
            "\n",
            "Test Data: (17838, 2)\n",
            "9342 Real\n",
            "8496 Fake\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43534</th>\n",
              "      <td>1</td>\n",
              "      <td>marco rubios economic proposals add  trillion ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15764</th>\n",
              "      <td>0</td>\n",
              "      <td>november    eduard popov fort russ  translated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40554</th>\n",
              "      <td>1</td>\n",
              "      <td>president bush eight years added  trillion deb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50229</th>\n",
              "      <td>1</td>\n",
              "      <td>greatest time may losing edge   jordan brand b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23399</th>\n",
              "      <td>0</td>\n",
              "      <td>november    pm trump fans may election arent t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>0</td>\n",
              "      <td>email get ready cringeworthy story youre going...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46139</th>\n",
              "      <td>1</td>\n",
              "      <td>says jimrenacci consistently voted loopholes e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7974</th>\n",
              "      <td>0</td>\n",
              "      <td>chart day explosion student loans vs implosion...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15119</th>\n",
              "      <td>0</td>\n",
              "      <td>politics leader islamic revolution ayatollah s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52126</th>\n",
              "      <td>1</td>\n",
              "      <td>almost us think starting business point though...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       label                                         clean_text\n",
              "43534      1  marco rubios economic proposals add  trillion ...\n",
              "15764      0  november    eduard popov fort russ  translated...\n",
              "40554      1  president bush eight years added  trillion deb...\n",
              "50229      1  greatest time may losing edge   jordan brand b...\n",
              "23399      0  november    pm trump fans may election arent t...\n",
              "76         0  email get ready cringeworthy story youre going...\n",
              "46139      1  says jimrenacci consistently voted loopholes e...\n",
              "7974       0  chart day explosion student loans vs implosion...\n",
              "15119      0  politics leader islamic revolution ayatollah s...\n",
              "52126      1  almost us think starting business point though..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loVZfYjMcGqr",
        "colab_type": "code",
        "outputId": "98b7ceca-3bf7-4b6c-e2e5-e582e653085a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            " Original:  marco rubios economic proposals add  trillion federal deficit\n",
            "Tokenized:  ['marco', 'rub', '##ios', 'economic', 'proposals', 'add', 'trillion', 'federal', 'deficit']\n",
            "Token IDs:  [8879, 14548, 10735, 3171, 10340, 5587, 23458, 2976, 15074]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJshyPp-ckKd",
        "colab_type": "code",
        "outputId": "b26f9f73-c358-41b9-d5d6-fd34c43868ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512  # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  marco rubios economic proposals add  trillion federal deficit\n",
            "Token IDs: [101, 8879, 14548, 10735, 3171, 10340, 5587, 23458, 2976, 15074, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifYzrz9uiwP_",
        "colab_type": "code",
        "outputId": "bf6db549-a7bc-4f95-8cec-c3943fc110d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import statistics\n",
        "\n",
        "print('Avg sentence length: ', statistics.mean([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg sentence length:  179.84809497943664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXHmv7yesVK",
        "colab_type": "code",
        "outputId": "993537d7-1f27-4d6b-ea33-3055898fddff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvyfN72VfWcV",
        "colab_type": "code",
        "outputId": "35c99831-97a9-4b11-ef3e-c2b28e902097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import keras\n",
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 256\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 256 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqNv5QsVfnUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCXPjlXIfsQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agaAZSoif3sS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dTJou7Of9cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3h6yiQbgClZ",
        "colab_type": "code",
        "outputId": "d2b7e802-2fc8-44c2-d8ed-231bfff41493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fd0ec3bdcd60446483916ceee132dfa3",
            "064b68a998574f9d945bd4df2bffde4c",
            "c32aefe41888479cb4d3b8263e81a157",
            "e1f539aebea44f68ab6ee7bdd5c02ec6",
            "647362e815ef4d4da8a074af927f8871",
            "630673e01de042458bfb3aad25682bef",
            "247a746e1877473a888a984df9c42fd1",
            "73254e8113bb4549977c1676af7b15d3",
            "65324e2fd407468fafb634a878659dcf",
            "b15b6414466e4a2e89d45eaf2c0b353e",
            "8785a7b52f46485a9b1844448d6eff78",
            "98ade063470c4cd9897c91b6f1527a2a",
            "9dc63dbd30fd4c8f98f7dbe9c01880f4",
            "b1756c429fb34d13853506ab5c22ffed",
            "e29a76f89c224672996a4ad3e6bf1019",
            "60ac98e959d2440f9f1e04203466cf4f"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd0ec3bdcd60446483916ceee132dfa3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65324e2fd407468fafb634a878659dcf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwhx9vhRgLSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk7UBXRngQ5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 5\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypIPojg2gecd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40nXss1egftg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPa5Ka6-iv5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99pr3Ra3gqgk",
        "colab_type": "code",
        "outputId": "38d6a8f9-b28a-401d-a127-63889369c1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.3f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of  1,813.    Elapsed: 0:00:30.\n",
            "  Batch    80  of  1,813.    Elapsed: 0:01:01.\n",
            "  Batch   120  of  1,813.    Elapsed: 0:01:31.\n",
            "  Batch   160  of  1,813.    Elapsed: 0:02:01.\n",
            "  Batch   200  of  1,813.    Elapsed: 0:02:31.\n",
            "  Batch   240  of  1,813.    Elapsed: 0:03:02.\n",
            "  Batch   280  of  1,813.    Elapsed: 0:03:32.\n",
            "  Batch   320  of  1,813.    Elapsed: 0:04:02.\n",
            "  Batch   360  of  1,813.    Elapsed: 0:04:32.\n",
            "  Batch   400  of  1,813.    Elapsed: 0:05:03.\n",
            "  Batch   440  of  1,813.    Elapsed: 0:05:33.\n",
            "  Batch   480  of  1,813.    Elapsed: 0:06:03.\n",
            "  Batch   520  of  1,813.    Elapsed: 0:06:33.\n",
            "  Batch   560  of  1,813.    Elapsed: 0:07:04.\n",
            "  Batch   600  of  1,813.    Elapsed: 0:07:34.\n",
            "  Batch   640  of  1,813.    Elapsed: 0:08:04.\n",
            "  Batch   680  of  1,813.    Elapsed: 0:08:35.\n",
            "  Batch   720  of  1,813.    Elapsed: 0:09:05.\n",
            "  Batch   760  of  1,813.    Elapsed: 0:09:35.\n",
            "  Batch   800  of  1,813.    Elapsed: 0:10:06.\n",
            "  Batch   840  of  1,813.    Elapsed: 0:10:36.\n",
            "  Batch   880  of  1,813.    Elapsed: 0:11:06.\n",
            "  Batch   920  of  1,813.    Elapsed: 0:11:36.\n",
            "  Batch   960  of  1,813.    Elapsed: 0:12:07.\n",
            "  Batch 1,000  of  1,813.    Elapsed: 0:12:37.\n",
            "  Batch 1,040  of  1,813.    Elapsed: 0:13:07.\n",
            "  Batch 1,080  of  1,813.    Elapsed: 0:13:38.\n",
            "  Batch 1,120  of  1,813.    Elapsed: 0:14:08.\n",
            "  Batch 1,160  of  1,813.    Elapsed: 0:14:38.\n",
            "  Batch 1,200  of  1,813.    Elapsed: 0:15:09.\n",
            "  Batch 1,240  of  1,813.    Elapsed: 0:15:39.\n",
            "  Batch 1,280  of  1,813.    Elapsed: 0:16:09.\n",
            "  Batch 1,320  of  1,813.    Elapsed: 0:16:39.\n",
            "  Batch 1,360  of  1,813.    Elapsed: 0:17:10.\n",
            "  Batch 1,400  of  1,813.    Elapsed: 0:17:40.\n",
            "  Batch 1,440  of  1,813.    Elapsed: 0:18:10.\n",
            "  Batch 1,480  of  1,813.    Elapsed: 0:18:41.\n",
            "  Batch 1,520  of  1,813.    Elapsed: 0:19:11.\n",
            "  Batch 1,560  of  1,813.    Elapsed: 0:19:41.\n",
            "  Batch 1,600  of  1,813.    Elapsed: 0:20:11.\n",
            "  Batch 1,640  of  1,813.    Elapsed: 0:20:42.\n",
            "  Batch 1,680  of  1,813.    Elapsed: 0:21:12.\n",
            "  Batch 1,720  of  1,813.    Elapsed: 0:21:42.\n",
            "  Batch 1,760  of  1,813.    Elapsed: 0:22:13.\n",
            "  Batch 1,800  of  1,813.    Elapsed: 0:22:43.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:22:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.849\n",
            "  Validation took: 0:00:49\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of  1,813.    Elapsed: 0:00:30.\n",
            "  Batch    80  of  1,813.    Elapsed: 0:01:01.\n",
            "  Batch   120  of  1,813.    Elapsed: 0:01:31.\n",
            "  Batch   160  of  1,813.    Elapsed: 0:02:01.\n",
            "  Batch   200  of  1,813.    Elapsed: 0:02:31.\n",
            "  Batch   240  of  1,813.    Elapsed: 0:03:02.\n",
            "  Batch   280  of  1,813.    Elapsed: 0:03:32.\n",
            "  Batch   320  of  1,813.    Elapsed: 0:04:02.\n",
            "  Batch   360  of  1,813.    Elapsed: 0:04:33.\n",
            "  Batch   400  of  1,813.    Elapsed: 0:05:03.\n",
            "  Batch   440  of  1,813.    Elapsed: 0:05:33.\n",
            "  Batch   480  of  1,813.    Elapsed: 0:06:03.\n",
            "  Batch   520  of  1,813.    Elapsed: 0:06:34.\n",
            "  Batch   560  of  1,813.    Elapsed: 0:07:04.\n",
            "  Batch   600  of  1,813.    Elapsed: 0:07:34.\n",
            "  Batch   640  of  1,813.    Elapsed: 0:08:05.\n",
            "  Batch   680  of  1,813.    Elapsed: 0:08:35.\n",
            "  Batch   720  of  1,813.    Elapsed: 0:09:05.\n",
            "  Batch   760  of  1,813.    Elapsed: 0:09:36.\n",
            "  Batch   800  of  1,813.    Elapsed: 0:10:06.\n",
            "  Batch   840  of  1,813.    Elapsed: 0:10:36.\n",
            "  Batch   880  of  1,813.    Elapsed: 0:11:07.\n",
            "  Batch   920  of  1,813.    Elapsed: 0:11:37.\n",
            "  Batch   960  of  1,813.    Elapsed: 0:12:07.\n",
            "  Batch 1,000  of  1,813.    Elapsed: 0:12:38.\n",
            "  Batch 1,040  of  1,813.    Elapsed: 0:13:08.\n",
            "  Batch 1,080  of  1,813.    Elapsed: 0:13:38.\n",
            "  Batch 1,120  of  1,813.    Elapsed: 0:14:09.\n",
            "  Batch 1,160  of  1,813.    Elapsed: 0:14:39.\n",
            "  Batch 1,200  of  1,813.    Elapsed: 0:15:09.\n",
            "  Batch 1,240  of  1,813.    Elapsed: 0:15:40.\n",
            "  Batch 1,280  of  1,813.    Elapsed: 0:16:10.\n",
            "  Batch 1,320  of  1,813.    Elapsed: 0:16:40.\n",
            "  Batch 1,360  of  1,813.    Elapsed: 0:17:11.\n",
            "  Batch 1,400  of  1,813.    Elapsed: 0:17:41.\n",
            "  Batch 1,440  of  1,813.    Elapsed: 0:18:11.\n",
            "  Batch 1,480  of  1,813.    Elapsed: 0:18:42.\n",
            "  Batch 1,520  of  1,813.    Elapsed: 0:19:12.\n",
            "  Batch 1,560  of  1,813.    Elapsed: 0:19:42.\n",
            "  Batch 1,600  of  1,813.    Elapsed: 0:20:13.\n",
            "  Batch 1,640  of  1,813.    Elapsed: 0:20:43.\n",
            "  Batch 1,680  of  1,813.    Elapsed: 0:21:13.\n",
            "  Batch 1,720  of  1,813.    Elapsed: 0:21:44.\n",
            "  Batch 1,760  of  1,813.    Elapsed: 0:22:14.\n",
            "  Batch 1,800  of  1,813.    Elapsed: 0:22:44.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:22:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.874\n",
            "  Validation took: 0:00:49\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of  1,813.    Elapsed: 0:00:30.\n",
            "  Batch    80  of  1,813.    Elapsed: 0:01:01.\n",
            "  Batch   120  of  1,813.    Elapsed: 0:01:31.\n",
            "  Batch   160  of  1,813.    Elapsed: 0:02:01.\n",
            "  Batch   200  of  1,813.    Elapsed: 0:02:31.\n",
            "  Batch   240  of  1,813.    Elapsed: 0:03:02.\n",
            "  Batch   280  of  1,813.    Elapsed: 0:03:32.\n",
            "  Batch   320  of  1,813.    Elapsed: 0:04:02.\n",
            "  Batch   360  of  1,813.    Elapsed: 0:04:33.\n",
            "  Batch   400  of  1,813.    Elapsed: 0:05:03.\n",
            "  Batch   440  of  1,813.    Elapsed: 0:05:33.\n",
            "  Batch   480  of  1,813.    Elapsed: 0:06:03.\n",
            "  Batch   520  of  1,813.    Elapsed: 0:06:34.\n",
            "  Batch   560  of  1,813.    Elapsed: 0:07:04.\n",
            "  Batch   600  of  1,813.    Elapsed: 0:07:34.\n",
            "  Batch   640  of  1,813.    Elapsed: 0:08:04.\n",
            "  Batch   680  of  1,813.    Elapsed: 0:08:35.\n",
            "  Batch   720  of  1,813.    Elapsed: 0:09:05.\n",
            "  Batch   760  of  1,813.    Elapsed: 0:09:35.\n",
            "  Batch   800  of  1,813.    Elapsed: 0:10:05.\n",
            "  Batch   840  of  1,813.    Elapsed: 0:10:36.\n",
            "  Batch   880  of  1,813.    Elapsed: 0:11:06.\n",
            "  Batch   920  of  1,813.    Elapsed: 0:11:36.\n",
            "  Batch   960  of  1,813.    Elapsed: 0:12:07.\n",
            "  Batch 1,000  of  1,813.    Elapsed: 0:12:37.\n",
            "  Batch 1,040  of  1,813.    Elapsed: 0:13:07.\n",
            "  Batch 1,080  of  1,813.    Elapsed: 0:13:37.\n",
            "  Batch 1,120  of  1,813.    Elapsed: 0:14:08.\n",
            "  Batch 1,160  of  1,813.    Elapsed: 0:14:38.\n",
            "  Batch 1,200  of  1,813.    Elapsed: 0:15:08.\n",
            "  Batch 1,240  of  1,813.    Elapsed: 0:15:39.\n",
            "  Batch 1,280  of  1,813.    Elapsed: 0:16:09.\n",
            "  Batch 1,320  of  1,813.    Elapsed: 0:16:39.\n",
            "  Batch 1,360  of  1,813.    Elapsed: 0:17:09.\n",
            "  Batch 1,400  of  1,813.    Elapsed: 0:17:40.\n",
            "  Batch 1,440  of  1,813.    Elapsed: 0:18:10.\n",
            "  Batch 1,480  of  1,813.    Elapsed: 0:18:40.\n",
            "  Batch 1,520  of  1,813.    Elapsed: 0:19:11.\n",
            "  Batch 1,560  of  1,813.    Elapsed: 0:19:41.\n",
            "  Batch 1,600  of  1,813.    Elapsed: 0:20:11.\n",
            "  Batch 1,640  of  1,813.    Elapsed: 0:20:42.\n",
            "  Batch 1,680  of  1,813.    Elapsed: 0:21:12.\n",
            "  Batch 1,720  of  1,813.    Elapsed: 0:21:42.\n",
            "  Batch 1,760  of  1,813.    Elapsed: 0:22:12.\n",
            "  Batch 1,800  of  1,813.    Elapsed: 0:22:43.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:22:52\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.894\n",
            "  Validation took: 0:00:49\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of  1,813.    Elapsed: 0:00:30.\n",
            "  Batch    80  of  1,813.    Elapsed: 0:01:01.\n",
            "  Batch   120  of  1,813.    Elapsed: 0:01:31.\n",
            "  Batch   160  of  1,813.    Elapsed: 0:02:01.\n",
            "  Batch   200  of  1,813.    Elapsed: 0:02:32.\n",
            "  Batch   240  of  1,813.    Elapsed: 0:03:02.\n",
            "  Batch   280  of  1,813.    Elapsed: 0:03:32.\n",
            "  Batch   320  of  1,813.    Elapsed: 0:04:03.\n",
            "  Batch   360  of  1,813.    Elapsed: 0:04:33.\n",
            "  Batch   400  of  1,813.    Elapsed: 0:05:03.\n",
            "  Batch   440  of  1,813.    Elapsed: 0:05:33.\n",
            "  Batch   480  of  1,813.    Elapsed: 0:06:04.\n",
            "  Batch   520  of  1,813.    Elapsed: 0:06:34.\n",
            "  Batch   560  of  1,813.    Elapsed: 0:07:04.\n",
            "  Batch   600  of  1,813.    Elapsed: 0:07:35.\n",
            "  Batch   640  of  1,813.    Elapsed: 0:08:05.\n",
            "  Batch   680  of  1,813.    Elapsed: 0:08:35.\n",
            "  Batch   720  of  1,813.    Elapsed: 0:09:06.\n",
            "  Batch   760  of  1,813.    Elapsed: 0:09:36.\n",
            "  Batch   800  of  1,813.    Elapsed: 0:10:06.\n",
            "  Batch   840  of  1,813.    Elapsed: 0:10:37.\n",
            "  Batch   880  of  1,813.    Elapsed: 0:11:07.\n",
            "  Batch   920  of  1,813.    Elapsed: 0:11:37.\n",
            "  Batch   960  of  1,813.    Elapsed: 0:12:07.\n",
            "  Batch 1,000  of  1,813.    Elapsed: 0:12:38.\n",
            "  Batch 1,040  of  1,813.    Elapsed: 0:13:08.\n",
            "  Batch 1,080  of  1,813.    Elapsed: 0:13:38.\n",
            "  Batch 1,120  of  1,813.    Elapsed: 0:14:09.\n",
            "  Batch 1,160  of  1,813.    Elapsed: 0:14:39.\n",
            "  Batch 1,200  of  1,813.    Elapsed: 0:15:09.\n",
            "  Batch 1,240  of  1,813.    Elapsed: 0:15:40.\n",
            "  Batch 1,280  of  1,813.    Elapsed: 0:16:10.\n",
            "  Batch 1,320  of  1,813.    Elapsed: 0:16:40.\n",
            "  Batch 1,360  of  1,813.    Elapsed: 0:17:11.\n",
            "  Batch 1,400  of  1,813.    Elapsed: 0:17:41.\n",
            "  Batch 1,440  of  1,813.    Elapsed: 0:18:11.\n",
            "  Batch 1,480  of  1,813.    Elapsed: 0:18:42.\n",
            "  Batch 1,520  of  1,813.    Elapsed: 0:19:12.\n",
            "  Batch 1,560  of  1,813.    Elapsed: 0:19:42.\n",
            "  Batch 1,600  of  1,813.    Elapsed: 0:20:13.\n",
            "  Batch 1,640  of  1,813.    Elapsed: 0:20:43.\n",
            "  Batch 1,680  of  1,813.    Elapsed: 0:21:13.\n",
            "  Batch 1,720  of  1,813.    Elapsed: 0:21:44.\n",
            "  Batch 1,760  of  1,813.    Elapsed: 0:22:14.\n",
            "  Batch 1,800  of  1,813.    Elapsed: 0:22:44.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:22:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.905\n",
            "  Validation took: 0:00:49\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "  Batch    40  of  1,813.    Elapsed: 0:00:30.\n",
            "  Batch    80  of  1,813.    Elapsed: 0:01:01.\n",
            "  Batch   120  of  1,813.    Elapsed: 0:01:31.\n",
            "  Batch   160  of  1,813.    Elapsed: 0:02:01.\n",
            "  Batch   200  of  1,813.    Elapsed: 0:02:32.\n",
            "  Batch   240  of  1,813.    Elapsed: 0:03:02.\n",
            "  Batch   280  of  1,813.    Elapsed: 0:03:32.\n",
            "  Batch   320  of  1,813.    Elapsed: 0:04:03.\n",
            "  Batch   360  of  1,813.    Elapsed: 0:04:33.\n",
            "  Batch   400  of  1,813.    Elapsed: 0:05:03.\n",
            "  Batch   440  of  1,813.    Elapsed: 0:05:34.\n",
            "  Batch   480  of  1,813.    Elapsed: 0:06:04.\n",
            "  Batch   520  of  1,813.    Elapsed: 0:06:34.\n",
            "  Batch   560  of  1,813.    Elapsed: 0:07:04.\n",
            "  Batch   600  of  1,813.    Elapsed: 0:07:35.\n",
            "  Batch   640  of  1,813.    Elapsed: 0:08:05.\n",
            "  Batch   680  of  1,813.    Elapsed: 0:08:35.\n",
            "  Batch   720  of  1,813.    Elapsed: 0:09:06.\n",
            "  Batch   760  of  1,813.    Elapsed: 0:09:36.\n",
            "  Batch   800  of  1,813.    Elapsed: 0:10:06.\n",
            "  Batch   840  of  1,813.    Elapsed: 0:10:37.\n",
            "  Batch   880  of  1,813.    Elapsed: 0:11:07.\n",
            "  Batch   920  of  1,813.    Elapsed: 0:11:37.\n",
            "  Batch   960  of  1,813.    Elapsed: 0:12:08.\n",
            "  Batch 1,000  of  1,813.    Elapsed: 0:12:38.\n",
            "  Batch 1,040  of  1,813.    Elapsed: 0:13:08.\n",
            "  Batch 1,080  of  1,813.    Elapsed: 0:13:39.\n",
            "  Batch 1,120  of  1,813.    Elapsed: 0:14:09.\n",
            "  Batch 1,160  of  1,813.    Elapsed: 0:14:39.\n",
            "  Batch 1,200  of  1,813.    Elapsed: 0:15:10.\n",
            "  Batch 1,240  of  1,813.    Elapsed: 0:15:40.\n",
            "  Batch 1,280  of  1,813.    Elapsed: 0:16:10.\n",
            "  Batch 1,320  of  1,813.    Elapsed: 0:16:41.\n",
            "  Batch 1,360  of  1,813.    Elapsed: 0:17:11.\n",
            "  Batch 1,400  of  1,813.    Elapsed: 0:17:41.\n",
            "  Batch 1,440  of  1,813.    Elapsed: 0:18:11.\n",
            "  Batch 1,480  of  1,813.    Elapsed: 0:18:42.\n",
            "  Batch 1,520  of  1,813.    Elapsed: 0:19:12.\n",
            "  Batch 1,560  of  1,813.    Elapsed: 0:19:42.\n",
            "  Batch 1,600  of  1,813.    Elapsed: 0:20:13.\n",
            "  Batch 1,640  of  1,813.    Elapsed: 0:20:43.\n",
            "  Batch 1,680  of  1,813.    Elapsed: 0:21:13.\n",
            "  Batch 1,720  of  1,813.    Elapsed: 0:21:44.\n",
            "  Batch 1,760  of  1,813.    Elapsed: 0:22:14.\n",
            "  Batch 1,800  of  1,813.    Elapsed: 0:22:44.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:22:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.909\n",
            "  Validation took: 0:00:49\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IHTecLQurXmB",
        "outputId": "650a0792-5ece-4aad-ee52-61ae9ba6dfbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "outputId": "45cdcc88-4292-4958-e0e2-f3c2d0b0ed4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(test_data.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test_data.clean_text.values\n",
        "labels = test_data.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        max_length = 512,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 17,838\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArHjZRsVo9B",
        "colab_type": "code",
        "outputId": "d695aaf0-3038-49aa-8e06-14f1ea0ebd6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions, true_labels = [], []\n",
        "test_loss, test_accuracy = 0, 0\n",
        "nb_test_steps, nb_test_examples = 0, 0\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # # Store predictions and true labels\n",
        "  # predictions.append(logits)\n",
        "  # true_labels.append(label_ids)\n",
        "\n",
        "  # Calculate the accuracy for this batch of test sentences.\n",
        "  tmp_test_accuracy = flat_accuracy(logits, label_ids)\n",
        "  \n",
        "  # Accumulate the total accuracy.\n",
        "  test_accuracy += tmp_test_accuracy\n",
        "\n",
        "  # Track the number of batches\n",
        "  nb_test_steps += 1\n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "print(\"Testing Accuracy: {0:.3f}\".format(test_accuracy/nb_test_steps))\n",
        "print('    DONE.')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 17,838 test sentences...\n",
            "Testing Accuracy: 0.946\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64XiQuhLlclp",
        "colab_type": "code",
        "outputId": "69fdb66c-df58-4bed-de1e-fa08a3367a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './saved_model_bt_augmented/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./saved_model_bt_augmented/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./saved_model_bt_augmented/vocab.txt',\n",
              " './saved_model_bt_augmented/special_tokens_map.json',\n",
              " './saved_model_bt_augmented/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMxcp0Sclhd_",
        "colab_type": "code",
        "outputId": "4df2a365-6f44-4462-e192-a6422890dd89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1DiMLXJmLLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./saved_model_bt_augmented/ \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2Ph2ltNmN7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "output_dir = '/content/drive/My Drive/saved_model_bt_augmented/'\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def predict(text, model):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  encoded_text = tokenizer.encode(\n",
        "                        text,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 512\n",
        "                   )\n",
        "  input_ids.append(encoded_text)\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                            value=0, truncating=\"post\", padding=\"post\")\n",
        "  \n",
        "  \n",
        "  attention_masks = []\n",
        "  att_mask = [int(token_id > 0) for token_id in input_ids[0]]\n",
        "  attention_masks.append(att_mask)\n",
        "\n",
        "  inputs = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  pred = model(inputs, token_type_ids=None, \n",
        "                      attention_mask=attention_masks)[0].argmax().item()\n",
        "  if (pred == 0.0):\n",
        "    print(\"Fake News\")\n",
        "  else:\n",
        "    print(\"Real News\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}